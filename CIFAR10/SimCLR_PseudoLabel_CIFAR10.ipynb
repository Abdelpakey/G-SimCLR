{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SimCLR_PseudoLabel_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariG23498/SimCLR_PseudoLabel/blob/master/CIFAR10/SimCLR_PseudoLabel_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r2eKarqEa6Jq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3838c05-2e38-4292-faab-f85ab5f7c764"
      },
      "source": [
        "# TensorFlow Imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lHIQyrTzbDdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "562abc8f-82f3-4d5e-998b-b44cba86a18b"
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 21 07:19:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9psdSeZuVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "79904f67-9ef6-4477-92ac-582d448d100c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-21 07:19:35--  https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6064 (5.9K) [text/plain]\n",
            "Saving to: ‘resnet_cifar10.py’\n",
            "\n",
            "\rresnet_cifar10.py     0%[                    ]       0  --.-KB/s               \rresnet_cifar10.py   100%[===================>]   5.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-08-21 07:19:36 (73.6 MB/s) - ‘resnet_cifar10.py’ saved [6064/6064]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxXT3bKVbjlo",
        "colab": {}
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import resnet_cifar10\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNS3zVGZuVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ResNetCIFAR10\n",
        "n = 4\n",
        "depth =  n * 9 + 2\n",
        "n_blocks = ((depth - 2) // 9) - 1\n",
        "\n",
        "# The input tensor\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# The Stem Convolution Group\n",
        "x = resnet_cifar10.stem(inputs)\n",
        "   \n",
        "# The learner\n",
        "outputs = resnet_cifar10.learner(x, n_blocks)\n",
        "\n",
        "# Instantiate the Model\n",
        "resnet_headless_model = Model(inputs, outputs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20oIWhxZuVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19d28413-fa91-4a68-94f0-c28d441e6af7"
      },
      "source": [
        "resnet_headless_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 32, 32, 16)   64          conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_164 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 16)   272         re_lu_164[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 32, 32, 16)   64          conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_165 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_165[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 32, 32, 16)   64          conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_166 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_166[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_164[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 32, 32, 64)   256         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 32, 32, 64)   0           conv2d_167[0][0]                 \n",
            "                                                                 batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_167 (ReLU)                (None, 32, 32, 64)   0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_167[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 32, 32, 16)   64          conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_168 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_168[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 32, 32, 16)   64          conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_169 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_169[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 32, 32, 64)   256         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 32, 32, 64)   0           batch_normalization_170[0][0]    \n",
            "                                                                 re_lu_167[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_170 (ReLU)                (None, 32, 32, 64)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_170[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 32, 32, 16)   64          conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_171 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_171[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 32, 32, 16)   64          conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_172 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_172[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 32, 32, 64)   256         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 32, 32, 64)   0           batch_normalization_173[0][0]    \n",
            "                                                                 re_lu_170[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_173 (ReLU)                (None, 32, 32, 64)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_173[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 32, 32, 16)   64          conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_174 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_174[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 32, 32, 16)   64          conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_175 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_175[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 32, 32, 64)   256         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 64)   0           batch_normalization_176[0][0]    \n",
            "                                                                 re_lu_173[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_176 (ReLU)                (None, 32, 32, 64)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 32, 32, 64)   4160        re_lu_176[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 32, 32, 64)   256         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_177 (ReLU)                (None, 32, 32, 64)   0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_177[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 16, 16, 64)   256         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_178 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_178[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_176[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 16, 16, 128)  512         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 16, 16, 128)  0           conv2d_180[0][0]                 \n",
            "                                                                 batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_179 (ReLU)                (None, 16, 16, 128)  0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_179[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 16, 16, 64)   256         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_180 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_180[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 16, 16, 64)   256         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_181 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_181[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 16, 16, 128)  512         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 128)  0           batch_normalization_182[0][0]    \n",
            "                                                                 re_lu_179[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_182 (ReLU)                (None, 16, 16, 128)  0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_182[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 16, 16, 64)   256         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_183 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_183[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 16, 16, 64)   256         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_184 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_184[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 16, 16, 128)  512         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 128)  0           batch_normalization_185[0][0]    \n",
            "                                                                 re_lu_182[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_185 (ReLU)                (None, 16, 16, 128)  0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_185[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 16, 16, 64)   256         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_186 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_186[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 16, 16, 64)   256         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_187 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_187[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 16, 16, 128)  512         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 16, 16, 128)  0           batch_normalization_188[0][0]    \n",
            "                                                                 re_lu_185[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_188 (ReLU)                (None, 16, 16, 128)  0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 128)  16512       re_lu_188[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 16, 16, 128)  512         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_189 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_189[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 128)    512         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_190 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_190[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_188[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 256)    1024        conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 8, 8, 256)    0           conv2d_193[0][0]                 \n",
            "                                                                 batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_191 (ReLU)                (None, 8, 8, 256)    0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_191[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 128)    512         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_192 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_192[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 128)    512         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_193 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_193[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 256)    1024        conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n",
            "                                                                 re_lu_191[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_194 (ReLU)                (None, 8, 8, 256)    0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 128)    512         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_195 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_195[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 128)    512         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_196 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_196[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 256)    1024        conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 8, 8, 256)    0           batch_normalization_197[0][0]    \n",
            "                                                                 re_lu_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_197 (ReLU)                (None, 8, 8, 256)    0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_197[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 128)    512         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_198 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_198[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 128)    512         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_199 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_199[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 8, 8, 256)    1024        conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 8, 8, 256)    0           batch_normalization_200[0][0]    \n",
            "                                                                 re_lu_197[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_200 (ReLU)                (None, 8, 8, 256)    0           add_65[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,121,344\n",
            "Trainable params: 1,114,400\n",
            "Non-trainable params: 6,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p97R8dh6ruHl",
        "colab_type": "text"
      },
      "source": [
        "## The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__VH51b3b2dG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "735453a9-ec18-416e-d715-e0d792a7ef44"
      },
      "source": [
        "# Load the training set of CIFAR10\n",
        "(X_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train/255.\n",
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zplbJ9M-sNAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "1db78de9-3a49-4d44-991d-a24805829a2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-8CNXBusWXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Colab\\ Notebooks/Souradip\\ Sayak/SimCLR_PseudoLabels/Models/20200821-060112autoencoder_cifar10.h5 ."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bkrUYGVueDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auto_model = tf.keras.models.load_model('20200821-060112autoencoder_cifar10.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCYL_JwOuuqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59137738-5a8c-413a-f888-ac1e79251d65"
      },
      "source": [
        "auto_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "retrieval (MaxPooling2D)     (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "auto_output (Conv2D)         (None, 32, 32, 3)         867       \n",
            "=================================================================\n",
            "Total params: 335,747\n",
            "Trainable params: 334,851\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB-uV7ZGuxHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "84dc9186-afbd-4ac1-a24a-a39b79587163"
      },
      "source": [
        "layer_name = 'retrieval'\n",
        "slice_model = tf.keras.Model(\n",
        "    inputs=auto_model.input,\n",
        "    outputs=auto_model.get_layer(layer_name).output\n",
        "    )\n",
        "slice_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "retrieval (MaxPooling2D)     (None, 4, 4, 128)         0         \n",
            "=================================================================\n",
            "Total params: 94,144\n",
            "Trainable params: 93,696\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVR5GO8vu6Aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_train = slice_model.predict(X_train)\n",
        "embedding_train = tf.keras.layers.GlobalAveragePooling2D()(latent_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9DAwWkKvLPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMVX6At6rwR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cb2ed8d-7e72-4aa6-cd8e-857db050d7b5"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "classifier = KMeans(n_clusters=BATCH_SIZE, random_state=0).fit(embedding_train)\n",
        "# labels of the clusters\n",
        "labels = classifier.labels_\n",
        "labels.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5J421j1rxhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hJ0mMfr0ZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8d092e87-acb8-4755-e466-9f9045905402"
      },
      "source": [
        "# Building the DataFrame\n",
        "df = pd.DataFrame()\n",
        "df['cluster_labels'] = labels\n",
        "df['imag_ind'] = np.arange(0,len(df))\n",
        "df = df[['imag_ind','cluster_labels']]\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   imag_ind  cluster_labels\n",
              "0         0              39\n",
              "1         1              57\n",
              "2         2              61\n",
              "3         3               1\n",
              "4         4              41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO0oWeo5r5Yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9b715eec-7a0d-4295-98c7-efb286fdd6cf"
      },
      "source": [
        "# The rank according to the cluster_labels\n",
        "df[\"rank\"] = df.groupby(\"cluster_labels\")[\"imag_ind\"].rank(\"dense\", ascending=True)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   imag_ind  cluster_labels  rank\n",
              "0         0              39   1.0\n",
              "1         1              57   1.0\n",
              "2         2              61   1.0\n",
              "3         3               1   1.0\n",
              "4         4              41   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpZrxp0Tr5PO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ed828192-7b61-4559-ce8d-3ad32e3f34d5"
      },
      "source": [
        "# Sorting the labels by cluster_labels and rank\n",
        "df_data = df.sort_values(by = ['cluster_labels','rank'])\n",
        "df_data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>282</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     imag_ind  cluster_labels  rank\n",
              "7           7               0   1.0\n",
              "52         52               0   2.0\n",
              "113       113               0   3.0\n",
              "143       143               0   4.0\n",
              "282       282               0   5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVw8w0gyr5Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "29078053-6c79-498f-ceec-43c65cad2cd0"
      },
      "source": [
        "# Sort with respect to rank only\n",
        "df_data2 = df_data.sort_values(by = ['rank'])\n",
        "df_data2.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>47</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>49</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    imag_ind  cluster_labels  rank\n",
              "7          7               0   1.0\n",
              "82        82              47   1.0\n",
              "57        57              48   1.0\n",
              "92        92              49   1.0\n",
              "20        20              13   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEwNR7msBvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ff058d8-c7f5-479d-ac6e-426f5ac7088b"
      },
      "source": [
        "arr_ind = df_data2['imag_ind'].values\n",
        "X_train = X_train[arr_ind]\n",
        "X_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYHjsLamsI4B",
        "colab_type": "text"
      },
      "source": [
        "## Continuation with SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4csOqgEZb8MP",
        "colab": {}
      },
      "source": [
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):\n",
        "        \n",
        "        # Random flips\n",
        "        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "        \n",
        "        # randomly apply transformation (color distortions and blur) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=0.5)\n",
        "        sample = self._random_apply(self._color_drop, sample, p=0.5)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x, s=0.2):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _color_drop(self, x):\n",
        "        image = tf.image.rgb_to_grayscale(x)\n",
        "        image = tf.tile(x, [1, 1, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfNCi9M2ZuVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_augmentation = Sequential([Lambda(CustomAugment())])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lt_IV81xc_sW",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "# # Create TensorFlow dataset\n",
        "# def normalize(image):\n",
        "#     return tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train))\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    # .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    # .cache()\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzrjGfJ0ZuV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "58a7ad5c-80c6-498e-9890-b0314d7f2968"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-21 07:23:41--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘helpers.py’\n",
            "\n",
            "\rhelpers.py            0%[                    ]       0  --.-KB/s               \rhelpers.py          100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2020-08-21 07:23:42 (49.3 MB/s) - ‘helpers.py’ saved [891/891]\n",
            "\n",
            "--2020-08-21 07:23:45--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘losses.py’\n",
            "\n",
            "losses.py           100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2020-08-21 07:23:45 (49.6 MB/s) - ‘losses.py’ saved [891/891]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvEQyVmHP-vP",
        "colab_type": "text"
      },
      "source": [
        "Don't forget to comment the augmentation import in the `helpers.py` script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LEpyZJQDjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from losses import _dot_simililarity_dim1 as sim_func_dim1, _dot_simililarity_dim2 as sim_func_dim2\n",
        "import helpers"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACHBh0MfQInT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mask to remove positive examples from the batch of negative samples\n",
        "negative_mask = helpers.get_negative_mask(BATCH_SIZE)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0dG8RWfZuWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Architecture utils\n",
        "def get_resnet_simclr_deeper(hidden_1, hidden_2, hidden_3):\n",
        "    inputs = Input((32, 32, 3))\n",
        "    h = resnet_headless_model(inputs, training=True)\n",
        "    h = GlobalAveragePooling2D()(h)\n",
        "    \n",
        "    projection_1 = Dense(hidden_1)(h)\n",
        "    projection_1 = Activation(\"relu\")(projection_1)\n",
        "    projection_2 = Dense(hidden_2)(projection_1)\n",
        "    projection_2 = Activation(\"relu\")(projection_2)\n",
        "    projection_3 = Dense(hidden_3)(projection_2)\n",
        "\n",
        "    resnet_simclr = Model(inputs, projection_3)\n",
        "\n",
        "    return resnet_simclr"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DwbPUDNCuU8F",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        zis = model(xis)\n",
        "        zjs = model(xjs)\n",
        "\n",
        "        # normalize projection feature vectors\n",
        "        zis = tf.math.l2_normalize(zis, axis=1)\n",
        "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
        "\n",
        "        l_pos = sim_func_dim1(zis, zjs)\n",
        "        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n",
        "        l_pos /= temperature\n",
        "\n",
        "        negatives = tf.concat([zjs, zis], axis=0)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for positives in [zis, zjs]:\n",
        "            l_neg = sim_func_dim2(positives, negatives)\n",
        "\n",
        "            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n",
        "\n",
        "            l_neg = tf.boolean_mask(l_neg, negative_mask)\n",
        "            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1))\n",
        "            l_neg /= temperature\n",
        "\n",
        "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
        "            loss += criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "        loss = loss / (2 * BATCH_SIZE)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uym2xu_tQ0wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_simclr(model, dataset, optimizer, criterion,\n",
        "                 temperature=0.1, epochs=100):\n",
        "    step_wise_loss = []\n",
        "    epoch_wise_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for image_batch in dataset:\n",
        "            a = data_augmentation(image_batch)\n",
        "            b = data_augmentation(image_batch)\n",
        "\n",
        "            loss = train_step(a, b, model, optimizer, criterion, temperature)\n",
        "            step_wise_loss.append(loss)\n",
        "\n",
        "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
        "\n",
        "    return epoch_wise_loss, model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4EtTFFAZuWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "a41cae5f-fe5e-48c7-9692-46865ebd8b7c"
      },
      "source": [
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
        "\n",
        "# Train SimCLR with SGD with CosineDecay restarts\n",
        "first_decay_steps = 1000\n",
        "lr_decayed_fn = (\n",
        "  tf.keras.experimental.CosineDecayRestarts(\n",
        "      initial_learning_rate=0.1,\n",
        "      first_decay_steps=first_decay_steps))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "resnet_simclr_2 = get_resnet_simclr_deeper(256, 128, 50)\n",
        "\n",
        "epoch_wise_loss, resnet_simclr  = train_simclr(resnet_simclr_2, train_ds, \n",
        "    optimizer, criterion,\n",
        "    temperature=0.1, epochs=15)\n",
        "\n",
        "with plt.xkcd():\n",
        "    plt.plot(epoch_wise_loss)\n",
        "    plt.title(\"tau = 0.1, h1 = 256, h2 = 128, h3 = 50\")\n",
        "    plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lambda is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [02:57<41:18, 177.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: 0.253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 11/15 [31:08<11:18, 169.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 11 loss: 0.056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [42:28<00:00, 169.89s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJuFqQkaEHTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b45d0d79-5c30-46bb-fc81-7da482752e09"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jakp_JbbHzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_simclr_2.save_weights(\"autoenc_resnet_simclr_cifar10.h5\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP5MjQ_WEUnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r autoenc_resnet_simclr_cifar10.h5 /content/drive/My\\ Drive/Colab\\ Notebooks/Souradip\\ Sayak/SimCLR_PseudoLabels/Models/"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}